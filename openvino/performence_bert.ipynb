{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xcnick/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at /workspace/models/chinese_roberta_wwm_ext_pytorch were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 768]) torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "# PyTorch\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "torch_model = transformers.BertModel.from_pretrained(\n",
    "    \"/workspace/models/chinese_roberta_wwm_ext_pytorch\")\n",
    "torch_model.eval()\n",
    "\n",
    "# ONNXRuntime\n",
    "import onnxruntime as ort\n",
    "\n",
    "ort_session = ort.InferenceSession(\n",
    "    './onnx/bert_model.onnx', providers=['CPUExecutionProvider'])\n",
    "\n",
    "# OpenVINO\n",
    "from openvino.runtime import Core, AsyncInferQueue\n",
    "\n",
    "ie = Core()\n",
    "onnx_model_path = './onnx/bert_model.onnx'\n",
    "model_onnx = ie.read_model(model=onnx_model_path)\n",
    "input_layer = next(iter(model_onnx.inputs))\n",
    "compiled_model_onnx = ie.compile_model(\n",
    "    model=model_onnx,\n",
    "    device_name='CPU',\n",
    "    config={\"PERFORMANCE_HINT\": \"THROUGHPUT\"})\n",
    "request = compiled_model_onnx.create_infer_request()\n",
    "# INT8\n",
    "# ir_model_path = 'bert_model.xml'\n",
    "# model_ir = ie.read_model(model=ir_model_path)\n",
    "\n",
    "# input\n",
    "import numpy as np\n",
    "\n",
    "dummy_input = np.random.randint(\n",
    "    low=1,\n",
    "    high=torch_model.config.vocab_size - 1,\n",
    "    size=(1, 128),\n",
    "    dtype=np.int64)\n",
    "\n",
    "with torch.no_grad():\n",
    "    torch_output = torch_model(torch.tensor(dummy_input))\n",
    "ort_output = ort_session.run(None,\n",
    "                             {ort_session.get_inputs()[0].name: dummy_input})\n",
    "request.infer({input_layer.any_name: dummy_input})\n",
    "ov_output_0 = request.get_output_tensor(0).data\n",
    "ov_output_1 = request.get_output_tensor(1).data\n",
    "\n",
    "np.testing.assert_allclose(torch_output[0].numpy(), ort_output[0], rtol=1e-03, atol=1e-05)\n",
    "np.testing.assert_allclose(torch_output[0].numpy(), ov_output_0, rtol=1e-03, atol=1e-05)\n",
    "np.testing.assert_allclose(torch_output[1].numpy(), ort_output[1], rtol=1e-03, atol=1e-05)\n",
    "np.testing.assert_allclose(torch_output[1].numpy(), ov_output_1, rtol=1e-03, atol=1e-05)\n",
    "\n",
    "print(torch_output[0].shape, torch_output[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch: batch_size 1, seq_len 10, 1.69 s\n",
      "onnxruntime: batch_size 1, seq_len 10, 0.83 s\n",
      "openvino-fp32: batch_size 1, seq_len 10, 0.28 s\n",
      "pytorch: batch_size 1, seq_len 50, 2.98 s\n",
      "onnxruntime: batch_size 1, seq_len 50, 1.70 s\n",
      "openvino-fp32: batch_size 1, seq_len 50, 0.52 s\n",
      "pytorch: batch_size 1, seq_len 100, 3.14 s\n",
      "onnxruntime: batch_size 1, seq_len 100, 2.88 s\n",
      "openvino-fp32: batch_size 1, seq_len 100, 0.95 s\n",
      "pytorch: batch_size 1, seq_len 200, 4.26 s\n",
      "onnxruntime: batch_size 1, seq_len 200, 4.82 s\n",
      "openvino-fp32: batch_size 1, seq_len 200, 1.84 s\n",
      "pytorch: batch_size 1, seq_len 300, 6.07 s\n",
      "onnxruntime: batch_size 1, seq_len 300, 7.07 s\n",
      "openvino-fp32: batch_size 1, seq_len 300, 2.45 s\n",
      "pytorch: batch_size 1, seq_len 400, 8.18 s\n",
      "onnxruntime: batch_size 1, seq_len 400, 9.17 s\n",
      "openvino-fp32: batch_size 1, seq_len 400, 3.83 s\n",
      "pytorch: batch_size 1, seq_len 500, 10.49 s\n",
      "onnxruntime: batch_size 1, seq_len 500, 12.01 s\n",
      "openvino-fp32: batch_size 1, seq_len 500, 4.76 s\n",
      "pytorch: batch_size 4, seq_len 10, 2.68 s\n",
      "onnxruntime: batch_size 4, seq_len 10, 1.53 s\n",
      "openvino-fp32: batch_size 4, seq_len 10, 0.46 s\n",
      "pytorch: batch_size 4, seq_len 50, 4.17 s\n",
      "onnxruntime: batch_size 4, seq_len 50, 4.48 s\n",
      "openvino-fp32: batch_size 4, seq_len 50, 1.69 s\n",
      "pytorch: batch_size 4, seq_len 100, 7.35 s\n",
      "onnxruntime: batch_size 4, seq_len 100, 8.48 s\n",
      "openvino-fp32: batch_size 4, seq_len 100, 3.43 s\n",
      "pytorch: batch_size 4, seq_len 200, 11.65 s\n",
      "onnxruntime: batch_size 4, seq_len 200, 15.93 s\n",
      "openvino-fp32: batch_size 4, seq_len 200, 6.83 s\n",
      "pytorch: batch_size 4, seq_len 300, 16.34 s\n",
      "onnxruntime: batch_size 4, seq_len 300, 22.52 s\n",
      "openvino-fp32: batch_size 4, seq_len 300, 10.11 s\n",
      "pytorch: batch_size 4, seq_len 400, 22.78 s\n",
      "onnxruntime: batch_size 4, seq_len 400, 29.70 s\n",
      "openvino-fp32: batch_size 4, seq_len 400, 14.80 s\n",
      "pytorch: batch_size 4, seq_len 500, 38.24 s\n",
      "onnxruntime: batch_size 4, seq_len 500, 43.46 s\n",
      "openvino-fp32: batch_size 4, seq_len 500, 20.21 s\n",
      "pytorch: batch_size 8, seq_len 10, 3.30 s\n",
      "onnxruntime: batch_size 8, seq_len 10, 2.41 s\n",
      "openvino-fp32: batch_size 8, seq_len 10, 0.78 s\n",
      "pytorch: batch_size 8, seq_len 50, 7.24 s\n",
      "onnxruntime: batch_size 8, seq_len 50, 8.33 s\n",
      "openvino-fp32: batch_size 8, seq_len 50, 3.31 s\n",
      "pytorch: batch_size 8, seq_len 100, 10.61 s\n",
      "onnxruntime: batch_size 8, seq_len 100, 15.46 s\n",
      "openvino-fp32: batch_size 8, seq_len 100, 6.89 s\n",
      "pytorch: batch_size 8, seq_len 200, 17.55 s\n",
      "onnxruntime: batch_size 8, seq_len 200, 27.59 s\n",
      "openvino-fp32: batch_size 8, seq_len 200, 13.09 s\n",
      "pytorch: batch_size 8, seq_len 300, 36.82 s\n",
      "onnxruntime: batch_size 8, seq_len 300, 47.03 s\n",
      "openvino-fp32: batch_size 8, seq_len 300, 19.30 s\n",
      "pytorch: batch_size 8, seq_len 400, 52.99 s\n",
      "onnxruntime: batch_size 8, seq_len 400, 64.57 s\n",
      "openvino-fp32: batch_size 8, seq_len 400, 26.35 s\n",
      "pytorch: batch_size 8, seq_len 500, 73.91 s\n",
      "onnxruntime: batch_size 8, seq_len 500, 83.78 s\n",
      "openvino-fp32: batch_size 8, seq_len 500, 35.47 s\n",
      "pytorch: batch_size 16, seq_len 10, 4.08 s\n",
      "onnxruntime: batch_size 16, seq_len 10, 4.04 s\n",
      "openvino-fp32: batch_size 16, seq_len 10, 1.43 s\n",
      "pytorch: batch_size 16, seq_len 50, 10.55 s\n",
      "onnxruntime: batch_size 16, seq_len 50, 14.55 s\n",
      "openvino-fp32: batch_size 16, seq_len 50, 6.53 s\n",
      "pytorch: batch_size 16, seq_len 100, 17.91 s\n",
      "onnxruntime: batch_size 16, seq_len 100, 27.73 s\n",
      "openvino-fp32: batch_size 16, seq_len 100, 12.83 s\n",
      "pytorch: batch_size 16, seq_len 200, 39.49 s\n",
      "onnxruntime: batch_size 16, seq_len 200, 58.92 s\n",
      "openvino-fp32: batch_size 16, seq_len 200, 25.24 s\n",
      "pytorch: batch_size 16, seq_len 300, 70.28 s\n",
      "onnxruntime: batch_size 16, seq_len 300, 89.34 s\n",
      "openvino-fp32: batch_size 16, seq_len 300, 38.23 s\n",
      "pytorch: batch_size 16, seq_len 400, 92.51 s\n",
      "onnxruntime: batch_size 16, seq_len 400, 126.90 s\n",
      "openvino-fp32: batch_size 16, seq_len 400, 53.20 s\n",
      "pytorch: batch_size 16, seq_len 500, 139.52 s\n",
      "onnxruntime: batch_size 16, seq_len 500, 162.66 s\n",
      "openvino-fp32: batch_size 16, seq_len 500, 69.17 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "warm_up_iters = 10\n",
    "inference_iters = 100\n",
    "\n",
    "batch_size = [1, 4, 8, 16]\n",
    "seq_len = [10, 50, 100, 200, 300, 400, 500]\n",
    "for bs in batch_size:\n",
    "    for sl in seq_len:\n",
    "        dummy_input = np.random.randint(\n",
    "            low=1,\n",
    "            high=torch_model.config.vocab_size - 1,\n",
    "            size=(bs, sl),\n",
    "            dtype=np.int64)\n",
    "\n",
    "        # pytorch\n",
    "        # warm up\n",
    "        with torch.no_grad():\n",
    "            for _ in range(warm_up_iters):\n",
    "                torch_output = torch_model(torch.tensor(dummy_input))\n",
    "            # inference test\n",
    "            start_time = time.time()\n",
    "            for _ in range(inference_iters):\n",
    "                torch_model(torch.tensor(dummy_input))\n",
    "            torch_time = time.time() - start_time\n",
    "            print(f'pytorch: batch_size {bs}, seq_len {sl}, {torch_time:.2f} s')\n",
    "\n",
    "        # onnxruntime\n",
    "        ort_inputs = {ort_session.get_inputs()[0].name: dummy_input}\n",
    "        # warm up\n",
    "        for _ in range(warm_up_iters):\n",
    "            ort_session.run(None, ort_inputs)\n",
    "        # inference test\n",
    "        start_time = time.time()\n",
    "        for _ in range(inference_iters):\n",
    "            ort_session.run(None, ort_inputs)\n",
    "        ort_time = time.time() - start_time\n",
    "        print(f'onnxruntime: batch_size {bs}, seq_len {sl}, {ort_time:.2f} s')\n",
    "\n",
    "        # openvino\n",
    "        model_onnx.reshape([bs, sl])\n",
    "        compiled_model_onnx = ie.compile_model(\n",
    "            model=model_onnx,\n",
    "            device_name='CPU',\n",
    "            config={\"PERFORMANCE_HINT\": \"THROUGHPUT\"})\n",
    "        infer_queue = AsyncInferQueue(compiled_model_onnx, 16)\n",
    "        # warm up\n",
    "        for _ in range(warm_up_iters):\n",
    "            infer_queue.start_async(inputs={input_layer.any_name: dummy_input})\n",
    "        infer_queue.wait_all()\n",
    "        # inference test\n",
    "        start_time = time.time()\n",
    "        for _ in range(inference_iters):\n",
    "            infer_queue.start_async(inputs={input_layer.any_name: dummy_input})\n",
    "        infer_queue.wait_all()\n",
    "        ov_time = time.time() - start_time\n",
    "        print(f'openvino-fp32: batch_size {bs}, seq_len {sl}, {ov_time:.2f} s')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61839f7db1b217d44ea212fe58a09e6de221471dead234eee5ac733397de118b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
